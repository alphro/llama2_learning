# The following github repository is an introduction on how to prompt engineer and finetune using Llama2
Due to limitations in personal GPU, please refer to the Google Collab links to find code on how to do prompt engineering and 4bit tokenization for Llama2 on your own

## Google Collab Links:
### Fine-tuning LLama2: https://colab.research.google.com/drive/1MJ8lFC81RPjsIVtm5TBgClXOyihPc3Xj?usp=sharing

### Using Dolly to Instruction Tune Llama2: https://colab.research.google.com/drive/1_C0emK7lj7DQWBMsEgrnvtEIA9nSYLgo?usp=sharing

### Finetune TinyLlama with Direct Policy Optimization (DPO): https://colab.research.google.com/drive/1AP9jewCrK6uSItWeRBePbkY9EFiYiii4?usp=sharing

### Fine-tune LLama 2 with QLoRa and TRL: https://colab.research.google.com/drive/1SYpgFpcmtIUzdE7pxqknrM4ArCASfkFQ?usp=sharing
